{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5fc2bdf-fb12-42ad-8dc3-e03e805f26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import *\n",
    "from dataset import *\n",
    "from utils import *\n",
    "from trainer import *\n",
    "from tqdm import tqdm\n",
    "from matchloss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54992a38-545b-46cb-bd07-5261cbb682aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "device = 'cuda'\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c222e20-9e73-4f33-b92f-28a553180ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dst_train, dst_test= load_cifar10_data()\n",
    "clean_train_loader, clean_test_loader= load_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a71f838-0f2d-44fa-9984-a953e79395a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "images_all = []\n",
    "labels_all = []\n",
    "indices_class = [[] for c in range(num_classes)]\n",
    "\n",
    "images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
    "labels_all = [dst_train[i][1] for i in range(len(dst_train))]\n",
    "for i, lab in enumerate(labels_all):\n",
    "    indices_class[lab].append(i)\n",
    "images_all = torch.cat(images_all, dim=0).to(device)\n",
    "labels_all = torch.tensor(labels_all, dtype=torch.long, device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f0ad72-9bf8-4e4c-9e9c-0fd54b9c818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_images(n, c = 0): # get random n images from class c\n",
    "    idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "    return idx_shuffle, images_all[idx_shuffle], labels_all[idx_shuffle]\n",
    "\n",
    "def get_noises(idxs, noise):\n",
    "    noises = [noise[i] for i in idxs]\n",
    "    return torch.stack(noises).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ba08e0d-5fdd-47d3-b0f5-53b577c1783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clsmodel = ResNet18().cuda();\n",
    "clsmodel.train(); \n",
    "clsmodel = torch.nn.DataParallel(clsmodel)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "clsoptimizer = optim.SGD(clsmodel.parameters(), lr=learning_rate,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(clsoptimizer, T_max=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e116b55-6085-4db1-b745-95925d03be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "# net.load_state_dict(checkpoint['net'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f41925a-73b5-4984-8111-5a462589aada",
   "metadata": {},
   "source": [
    "Set a target for seed image. Initialize seed images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b56d01eb-6b4f-4c16-b3ef-9666fa872f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "target = 0\n",
    "ipc = 1  # of seed imags\n",
    "image_syn = torch.tensor(torch.zeros(ipc, 3, 32, 32), dtype=torch.float, requires_grad=True, device='cuda')\n",
    "label_syn = torch.tensor([target for _ in range(ipc)], dtype=torch.long, requires_grad=False, device='cuda').view(-1)\n",
    "\n",
    "optimizer_img = torch.optim.SGD([image_syn, ], lr=0.5, momentum=0.5) # optimizer_img for synthetic data\n",
    "optimizer_img.zero_grad()\n",
    "# criterion = nn.CrossEntropyLoss().to('cuda')\n",
    "\n",
    "net_parameters = list(clsmodel.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa729dd-9489-4be0-a45d-cc52800e838a",
   "metadata": {},
   "source": [
    "Select subset of samples for adding perturbation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f47fedbc-1017-47df-a26e-69a82c148155",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_idx, perturb_images, perturb_labels= get_images(256, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e765f18-8b60-4d87-abf7-5e9695cd4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.zeros([50000, 3, 32, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4601fcb8-c67e-4ed6-8e6c-687be8218728",
   "metadata": {},
   "source": [
    "Iteratively updating noise, seed image, and model weights. The algorithm in general follows overleaf draft. Might be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c2d3a3-3493-42c7-a64b-b78d3102becb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [01:03<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 43.610% (21805/50000)\n",
      " [==============================>..................................]  Step: 1s121ms | Tot: 1m44s | Total Loss: 2011.5716552734375  Classification loss: 2.6240115165710 94/200  0  \r"
     ]
    }
   ],
   "source": [
    "condition = True\n",
    "step_size = 0.001\n",
    "step_size_sync = 0.01\n",
    "epsilon = 8/255\n",
    "epoch = 0\n",
    "I = 200\n",
    "J= 2\n",
    "N = len(images_all)\n",
    "\n",
    "while condition:\n",
    "    \n",
    "    if epoch != 0 and epoch % 3 == 0:\n",
    "        np.save( 'noise5',noise.numpy())\n",
    "        np.save( 'synimg5', image_syn.detach().cpu().numpy())\n",
    "        step_size_sync = max(step_size_sync / 2, 0.0005)\n",
    "    clsmodel.train()\n",
    "    \n",
    "    idx = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in tqdm(range(N//batch_size + 1)):\n",
    "        batch_noise = []\n",
    "        leftl, rightl = batch_size * i, min(batch_size * (i+1), N)\n",
    "        images, labels = images_all[leftl:rightl].cuda(), labels_all[leftl:rightl].cuda()\n",
    "        perturb_img = None\n",
    "        for i, _ in enumerate(images):\n",
    "            # Update noise to images\n",
    "            batch_noise.append(noise[idx])\n",
    "            idx += 1\n",
    "        batch_noise = torch.stack(batch_noise).cuda()\n",
    "\n",
    "        perturb_img = Variable(images + batch_noise, requires_grad = False)\n",
    "        perturb_img = Variable(torch.clamp(perturb_img, 0, 1), requires_grad=False)\n",
    "\n",
    "            # perturb_img = Variable(images, requires_grad = False)\n",
    "        clsmodel.train()\n",
    "        clsmodel.zero_grad()\n",
    "        clsoptimizer.zero_grad()\n",
    "        output = clsmodel(perturb_img)\n",
    "        clsloss = criterion(output, labels)\n",
    "        clsloss.backward()\n",
    "        clsoptimizer.step()\n",
    "        _, predicted = output.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    print('Training Acc: %.3f%% (%d/%d)'% (100.*correct/total, correct, total))\n",
    "    scheduler.step()\n",
    "   \n",
    "    clsmodel.eval()\n",
    "    \n",
    "    for c in range(I):\n",
    "   \n",
    "         # the target gradients can be computed at very start to avoid repetition\n",
    "        pred_ = clsmodel(image_syn)\n",
    "        loss_ = criterion(pred_, label_syn)\n",
    "        gw_syn = torch.autograd.grad(loss_, net_parameters, create_graph=True)\n",
    "\n",
    "        perturb_img = Variable(perturb_images + get_noises(perturb_idx, noise), requires_grad = False)\n",
    "        perturb_img = Variable(torch.clamp(perturb_img, 0, 1), requires_grad=True)\n",
    "        perturb_img.retain_grad()\n",
    "\n",
    "        # gw_real = list((x.detach().clone() for x in gw_real))\n",
    "\n",
    "        pred = clsmodel(perturb_img)\n",
    "        loss = criterion(pred, perturb_labels)\n",
    "        gw_real = torch.autograd.grad(loss, net_parameters, create_graph = True)\n",
    "        # gw_real = list((x.detach().clone() for x in gw_real))\n",
    "\n",
    "        matchloss = match_loss(gw_syn, gw_real, 'ours') + 1 * loss_\n",
    "        \n",
    "        progress_bar(c, I, \"Total Loss: {}  Classification loss: {}\".format(matchloss, loss_))\n",
    "\n",
    "        matchloss.backward()\n",
    "        # img_optimizer.step()\n",
    "\n",
    "        eta = step_size * perturb_img.grad.data.sign() * (-1)\n",
    "        perturb_img = Variable(perturb_img.data + eta, requires_grad=True)\n",
    "        eta = torch.clamp(perturb_img.data - perturb_images.data, -epsilon, epsilon)\n",
    "        perturb_img = Variable(perturb_images.data + eta, requires_grad=True)\n",
    "        perturb_img = Variable(torch.clamp(perturb_img, 0, 1), requires_grad=True)\n",
    "\n",
    "        eta = torch.clamp(perturb_img.data - perturb_images.data, -epsilon, epsilon)\n",
    "        for i, delta in enumerate(eta):\n",
    "            noise[perturb_idx[i]] = delta.clone().detach().cpu()\n",
    "        \n",
    "        image_syn = Variable(image_syn + step_size_sync * image_syn.grad.data.sign() * (-1), requires_grad = True)\n",
    "        image_syn = Variable(torch.clamp(image_syn, 0, 1),requires_grad = True)\n",
    "        \n",
    "    clsmodel.eval()\n",
    "    correct = 0\n",
    "    total = image_syn.shape[0]\n",
    "    for img in image_syn:\n",
    "        pred = clsmodel(img.unsqueeze(0))\n",
    "        _, lb = pred.max(1)\n",
    "        correct += lb == target\n",
    "    print(f\"{correct.detach().cpu()[0]}/{total} sync images are in target class\")\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        test_(clsmodel, clean_test_loader, criterion)\n",
    "    \n",
    "            \n",
    "    epoch += 1 \n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1883078e-fae7-43ff-abe5-de27d48e06ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(noise.numpy(), 'noise.py')\n",
    "np.save(image_syn.detach().cpu().numpy(), 'synimg.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b9c47-6f87-4d57-a7de-9bef02357521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e520a038-3286-4c05-a3b0-9aa81397641c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
